#!/opt/venv/bin/python
# -*- coding: utf-8 -*-
"""
YOLO26 ROS1 Node with tracking, smoothing, and hysteresis support.
Ported from yolo26_ros2 (ROS2 Humble version).
"""
from __future__ import annotations

import os
import threading
import time
from collections import deque, Counter
from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional, Tuple

import numpy as np
import rospy

from sensor_msgs.msg import Image, CompressedImage
from std_msgs.msg import Header
from vision_msgs.msg import Detection2DArray, Detection2D, ObjectHypothesisWithPose, BoundingBox2D
from geometry_msgs.msg import Pose2D
from cv_bridge import CvBridge

import yaml
import cv2


@dataclass
class TrackState:
    """State for a tracked object with smoothing and hysteresis."""
    track_id: int
    smoothing_window: int
    # Bbox history: (cx, cy, w, h)
    bbox_history: deque = field(default_factory=deque)
    # Confidence history
    conf_history: deque = field(default_factory=deque)
    # Class history
    class_history: deque = field(default_factory=deque)
    # Hysteresis counters
    appear_count: int = 0
    disappear_count: int = 0
    # Whether this track is "confirmed" (passed appear threshold)
    confirmed: bool = False
    # Locked class (once confirmed, use most frequent class)
    locked_class: Optional[int] = None

    def __post_init__(self):
        self.bbox_history = deque(maxlen=self.smoothing_window)
        self.conf_history = deque(maxlen=self.smoothing_window)
        self.class_history = deque(maxlen=self.smoothing_window)

    def update(self, cx: float, cy: float, w: float, h: float, conf: float, cls: int) -> None:
        """Add new detection data."""
        self.bbox_history.append((cx, cy, w, h))
        self.conf_history.append(conf)
        self.class_history.append(cls)
        self.disappear_count = 0  # Reset disappear counter on detection

    def get_smoothed_bbox(self) -> Tuple[float, float, float, float]:
        """Get moving average of bbox."""
        if len(self.bbox_history) == 0:
            return 0.0, 0.0, 0.0, 0.0
        arr = np.array(self.bbox_history)
        return float(arr[:, 0].mean()), float(arr[:, 1].mean()), float(arr[:, 2].mean()), float(arr[:, 3].mean())

    def get_smoothed_conf(self) -> float:
        """Get moving average of confidence."""
        if len(self.conf_history) == 0:
            return 0.0
        return float(np.mean(self.conf_history))

    def get_stable_class(self) -> int:
        """Get most frequent class (mode) or locked class if confirmed."""
        if self.locked_class is not None:
            return self.locked_class
        if len(self.class_history) == 0:
            return -1
        counter = Counter(self.class_history)
        return counter.most_common(1)[0][0]

    def lock_class(self) -> None:
        """Lock the class to current most frequent."""
        if len(self.class_history) > 0:
            counter = Counter(self.class_history)
            self.locked_class = counter.most_common(1)[0][0]


def load_classes_yaml(path: str) -> Optional[Dict[int, str]]:
    """Load class names from YAML file."""
    if not path:
        return None
    if not os.path.exists(path):
        return None

    with open(path, "r", encoding="utf-8") as f:
        data = yaml.safe_load(f)

    # Format 1: {0: person, 1: bottle, ...}
    if isinstance(data, dict):
        out: Dict[int, str] = {}
        for k, v in data.items():
            try:
                ki = int(k)
            except Exception:
                continue
            if isinstance(v, str):
                out[ki] = v
        return out if out else None

    # Format 2: ["person", "bottle", ...]
    if isinstance(data, list):
        out = {i: str(name) for i, name in enumerate(data)}
        return out if out else None

    return None


class Yolo26Ros1Node:
    def __init__(self):
        # ---- params ----
        self.image_topic = rospy.get_param("~image_topic", "/camera/image_raw")
        self.detections_topic = rospy.get_param("~detections_topic", "/yolo26/detections")
        self.debug_image_topic = rospy.get_param("~debug_image_topic", "/yolo26/debug_image")
        self.image_transport = rospy.get_param("~image_transport", "raw")  # raw / compressed
        self.publish_debug_image = rospy.get_param("~publish_debug_image", True)
        self.enable_cv_display = rospy.get_param("~enable_cv_display", False)
        self.cv_window_name = rospy.get_param("~cv_window_name", "YOLO26 Detection")

        self.model_path = rospy.get_param("~model_path", os.environ.get("YOLO_MODEL", ""))
        self.device = rospy.get_param("~device", os.environ.get("YOLO_DEVICE", "0"))
        self.conf_thres = float(rospy.get_param("~conf_thres", os.environ.get("YOLO_CONF", "0.25")))
        self.iou_thres = float(rospy.get_param("~iou_thres", 0.45))
        self.max_det = int(rospy.get_param("~max_det", 300))
        self.half = rospy.get_param("~half", False)

        self.classes_yaml = rospy.get_param("~classes_yaml", "")
        self.use_class_names = rospy.get_param("~use_class_names", True)

        self.process_rate_hz = float(rospy.get_param("~process_rate_hz", 15.0))
        self.process_period_s = 1.0 / max(self.process_rate_hz, 0.1)

        # Direct camera capture (bypass ROS image topic)
        self.use_direct_camera = rospy.get_param("~use_direct_camera", False)
        self.camera_device = rospy.get_param("~camera_device", "/dev/video0")
        self.camera_width = int(rospy.get_param("~camera_width", 1280))
        self.camera_height = int(rospy.get_param("~camera_height", 720))
        self._cap = None

        # Tracking parameters
        self.enable_tracking = rospy.get_param("~enable_tracking", False)
        self.tracker = rospy.get_param("~tracker", "bytetrack.yaml")
        self.smoothing_window = int(rospy.get_param("~smoothing_window", 15))
        self.appear_frames = int(rospy.get_param("~appear_frames", 3))
        self.disappear_frames = int(rospy.get_param("~disappear_frames", 5))

        # Track states: track_id -> TrackState
        self._track_states: Dict[int, TrackState] = {}

        self.bridge = CvBridge()

        # ---- class names ----
        self.class_map: Optional[Dict[int, str]] = load_classes_yaml(self.classes_yaml)

        # ---- model ----
        self.model = self._load_model(self.model_path)

        # ---- pubs/subs ----
        self.pub_det = rospy.Publisher(self.detections_topic, Detection2DArray, queue_size=10)
        self.pub_dbg = rospy.Publisher(self.debug_image_topic, Image, queue_size=10) if self.publish_debug_image else None

        self._lock = threading.Lock()
        self._latest_frame: Optional[np.ndarray] = None
        self._latest_header: Optional[Header] = None
        self._last_infer_ts = 0.0

        # Subscribe raw or compressed, or use direct camera capture
        if self.use_direct_camera:
            self._init_direct_camera()
            rospy.loginfo(f"Direct camera capture: {self.camera_device} ({self.camera_width}x{self.camera_height})")
        elif self.image_transport.lower() == "compressed":
            topic = self.image_topic.rstrip("/") + "/compressed"
            self.sub_img = rospy.Subscriber(topic, CompressedImage, self._cb_compressed, queue_size=1, buff_size=2**24)
            rospy.loginfo(f"Subscribe: {topic} (sensor_msgs/CompressedImage)")
        else:
            self.sub_img = rospy.Subscriber(self.image_topic, Image, self._cb_raw, queue_size=1, buff_size=2**24)
            rospy.loginfo(f"Subscribe: {self.image_topic} (sensor_msgs/Image)")

        # Timer inference loop
        self.timer = rospy.Timer(rospy.Duration(self.process_period_s), self._on_timer)

        # OpenCV display setup
        self._display_img = None
        if self.enable_cv_display:
            rospy.on_shutdown(self._cleanup_cv_window)
            rospy.loginfo(f"OpenCV display enabled: {self.cv_window_name}")

        tracking_info = f"rate={self.process_rate_hz}Hz, tracking={self.enable_tracking}"
        if self.enable_tracking:
            tracking_info += f" (tracker={self.tracker}, smoothing={self.smoothing_window}, appear={self.appear_frames}, disappear={self.disappear_frames})"
        rospy.loginfo(f"yolo26_ros1 node started. {tracking_info}")

    def _cleanup_cv_window(self) -> None:
        """Cleanup OpenCV window on shutdown."""
        if self.enable_cv_display:
            cv2.destroyAllWindows()
        if self._cap is not None:
            self._cap.release()

    def _init_direct_camera(self) -> None:
        """Initialize direct camera capture with OpenCV."""
        self._cap = cv2.VideoCapture(self.camera_device, cv2.CAP_V4L2)
        if not self._cap.isOpened():
            rospy.logerr(f"Failed to open camera: {self.camera_device}")
            return

        # Set MJPEG format
        self._cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc('M', 'J', 'P', 'G'))
        self._cap.set(cv2.CAP_PROP_FRAME_WIDTH, self.camera_width)
        self._cap.set(cv2.CAP_PROP_FRAME_HEIGHT, self.camera_height)
        self._cap.set(cv2.CAP_PROP_FPS, 30)

        # Verify settings
        actual_w = int(self._cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        actual_h = int(self._cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        rospy.loginfo(f"Camera opened: {actual_w}x{actual_h}")

    def _load_model(self, model_path: str):
        if not model_path:
            rospy.logerr("Parameter 'model_path' is empty. Set model_path in launch file or YOLO_MODEL env.")
            return None
        if not os.path.exists(model_path):
            rospy.logerr(f"Model file not found: {model_path}")
            return None

        try:
            from ultralytics import YOLO
        except Exception as e:
            rospy.logerr(f"Failed to import ultralytics. Install it: pip install ultralytics. Error: {e}")
            return None

        try:
            model = YOLO(model_path)
            # If no classes_yaml given, try to use model.names
            if self.class_map is None:
                try:
                    names = getattr(model, "names", None)
                    if isinstance(names, dict):
                        self.class_map = {int(k): str(v) for k, v in names.items()}
                    elif isinstance(names, list):
                        self.class_map = {i: str(v) for i, v in enumerate(names)}
                except Exception:
                    pass

            rospy.loginfo(f"Loaded model: {model_path}")
            return model
        except Exception as e:
            rospy.logerr(f"Failed to load YOLO model: {e}")
            return None

    def _cb_raw(self, msg: Image) -> None:
        try:
            cv_img = self.bridge.imgmsg_to_cv2(msg, desired_encoding="bgr8")
        except Exception as e:
            rospy.logwarn_throttle(2.0, f"cv_bridge imgmsg_to_cv2 failed: {e}")
            return
        with self._lock:
            self._latest_frame = cv_img
            self._latest_header = msg.header

    def _cb_compressed(self, msg: CompressedImage) -> None:
        try:
            np_arr = np.frombuffer(msg.data, dtype=np.uint8)
            cv_img = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)
            if cv_img is None:
                raise RuntimeError("cv2.imdecode returned None")
        except Exception as e:
            rospy.logwarn_throttle(2.0, f"decode compressed image failed: {e}")
            return
        with self._lock:
            self._latest_frame = cv_img
            self._latest_header = msg.header

    def _on_timer(self, event) -> None:
        # Direct camera capture mode
        if self.use_direct_camera:
            if self._cap is None or not self._cap.isOpened():
                return
            ret, frame = self._cap.read()
            if not ret or frame is None:
                return
            header = Header()
            header.stamp = rospy.Time.now()
            header.frame_id = "camera"
        else:
            # Throttle if no frame
            with self._lock:
                frame = None if self._latest_frame is None else self._latest_frame.copy()
                header = self._latest_header

        if frame is None or header is None:
            return

        now = time.time()
        # Avoid reprocessing too fast if timer overlaps
        if now - self._last_infer_ts < (self.process_period_s * 0.5):
            return
        self._last_infer_ts = now

        if self.model is None:
            return

        det_msg, dbg_img = self._infer_and_make_msgs(frame, header)
        if det_msg is not None:
            self.pub_det.publish(det_msg)
        if self.pub_dbg is not None and dbg_img is not None:
            try:
                img_msg = self.bridge.cv2_to_imgmsg(dbg_img, encoding="bgr8")
                img_msg.header = header
                self.pub_dbg.publish(img_msg)
            except Exception as e:
                rospy.logwarn_throttle(2.0, f"publish debug image failed: {e}")

        # Store image for display in main thread
        if self.enable_cv_display:
            display_img = dbg_img if dbg_img is not None else frame
            self._display_img = display_img.copy()

    def _class_id_to_label(self, cls_id: int) -> str:
        if self.use_class_names and self.class_map and cls_id in self.class_map:
            return self.class_map[cls_id]
        return str(cls_id)

    def _get_or_create_track(self, track_id: int) -> TrackState:
        """Get existing track state or create new one."""
        if track_id not in self._track_states:
            self._track_states[track_id] = TrackState(
                track_id=track_id,
                smoothing_window=self.smoothing_window
            )
        return self._track_states[track_id]

    def _update_track_hysteresis(self, active_ids: set) -> None:
        """Update hysteresis counters for all tracks."""
        stale_ids = []
        for tid, state in self._track_states.items():
            if tid not in active_ids:
                # Track not detected this frame
                state.disappear_count += 1
                if state.disappear_count >= self.disappear_frames:
                    stale_ids.append(tid)
            else:
                # Track detected - update appear counter
                state.appear_count += 1
                if state.appear_count >= self.appear_frames and not state.confirmed:
                    state.confirmed = True
                    state.lock_class()  # Lock class once confirmed

        # Remove tracks that have disappeared for too long
        for tid in stale_ids:
            del self._track_states[tid]

    def _draw_stabilized_detections(self, frame: np.ndarray, detections: List[Tuple]) -> np.ndarray:
        """Draw stabilized detections on frame.

        Args:
            frame: BGR image
            detections: List of (track_id, cx, cy, w, h, conf, class_label)
        """
        img = frame.copy()
        for track_id, cx, cy, w, h, conf, class_label in detections:
            x1 = int(cx - w / 2)
            y1 = int(cy - h / 2)
            x2 = int(cx + w / 2)
            y2 = int(cy + h / 2)

            # Color based on track_id
            color = self._get_track_color(track_id)

            # Draw bounding box
            cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)

            # Label
            label = f"ID:{track_id} {class_label} {conf:.2f}"
            (tw, th), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 1)
            cv2.rectangle(img, (x1, y1 - th - 10), (x1 + tw, y1), color, -1)
            cv2.putText(img, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)

        return img

    def _get_track_color(self, track_id: int) -> Tuple[int, int, int]:
        """Generate consistent color for track ID."""
        np.random.seed(track_id * 13 + 7)
        return tuple(int(c) for c in np.random.randint(50, 255, 3))

    def _infer_and_make_msgs(self, frame_bgr: np.ndarray, header: Header) -> Tuple[Optional[Detection2DArray], Optional[np.ndarray]]:
        """Run inference and create ROS messages."""
        try:
            if self.enable_tracking:
                # Use ByteTrack for tracking with persist=True
                results = self.model.track(
                    source=frame_bgr,
                    device=self.device,
                    conf=self.conf_thres,
                    iou=self.iou_thres,
                    max_det=self.max_det,
                    half=self.half,
                    verbose=False,
                    tracker=self.tracker,
                    persist=True,
                )
            else:
                results = self.model.predict(
                    source=frame_bgr,
                    device=self.device,
                    conf=self.conf_thres,
                    iou=self.iou_thres,
                    max_det=self.max_det,
                    half=self.half,
                    verbose=False,
                )
        except Exception as e:
            rospy.logwarn_throttle(2.0, f"model inference failed: {e}")
            return None, None

        if not results:
            det_arr = Detection2DArray()
            det_arr.header = header
            return det_arr, frame_bgr

        r0 = results[0]

        det_arr = Detection2DArray()
        det_arr.header = header

        # boxes
        try:
            boxes = getattr(r0, "boxes", None)
            if boxes is None:
                dbg_img = frame_bgr if self.publish_debug_image else None
                return det_arr, dbg_img

            xyxy = boxes.xyxy.cpu().numpy()  # (N,4)
            conf = boxes.conf.cpu().numpy()  # (N,)
            cls = boxes.cls.cpu().numpy().astype(int)  # (N,)

            # Get track IDs if tracking is enabled
            track_ids = None
            if self.enable_tracking and boxes.id is not None:
                track_ids = boxes.id.cpu().numpy().astype(int)
        except Exception as e:
            rospy.logwarn_throttle(2.0, f"extract boxes failed: {e}")
            dbg_img = frame_bgr if self.publish_debug_image else None
            return det_arr, dbg_img

        active_track_ids = set()
        stabilized_detections = []  # For custom debug rendering

        for i, ((x1, y1, x2, y2), score, cid) in enumerate(zip(xyxy, conf, cls)):
            x1f, y1f, x2f, y2f = float(x1), float(y1), float(x2), float(y2)
            w = max(0.0, x2f - x1f)
            h = max(0.0, y2f - y1f)
            cx = x1f + w / 2.0
            cy = y1f + h / 2.0

            track_id = -1
            final_cx, final_cy, final_w, final_h = cx, cy, w, h
            final_conf = float(score)
            final_class = int(cid)

            if self.enable_tracking and track_ids is not None:
                track_id = int(track_ids[i])
                active_track_ids.add(track_id)

                # Get or create track state
                state = self._get_or_create_track(track_id)
                state.update(cx, cy, w, h, float(score), int(cid))

                # Apply smoothing
                final_cx, final_cy, final_w, final_h = state.get_smoothed_bbox()
                final_conf = state.get_smoothed_conf()
                final_class = state.get_stable_class()

                # Skip if not yet confirmed (hysteresis)
                if not state.confirmed:
                    continue

            det = Detection2D()
            det.header = Header()
            det.header.stamp = header.stamp
            # Store tracking ID in frame_id (ROS1 Detection2D has no 'id' field)
            det.header.frame_id = str(track_id) if track_id >= 0 else ""

            bbox = BoundingBox2D()
            bbox.center = Pose2D(x=final_cx, y=final_cy, theta=0.0)
            bbox.size_x = final_w
            bbox.size_y = final_h
            det.bbox = bbox

            hyp = ObjectHypothesisWithPose()
            # ROS1 vision_msgs: id is int64, score is float64 (no nested hypothesis)
            hyp.id = final_class
            hyp.score = final_conf
            det.results.append(hyp)

            det_arr.detections.append(det)

            # Store for debug rendering
            if self.publish_debug_image:
                class_label = self._class_id_to_label(final_class)
                stabilized_detections.append((track_id, final_cx, final_cy, final_w, final_h, final_conf, class_label))

        # Update hysteresis for all tracks
        if self.enable_tracking:
            self._update_track_hysteresis(active_track_ids)

        # Debug image
        dbg_img = None
        if self.publish_debug_image:
            if self.enable_tracking:
                # Use custom stabilized rendering
                dbg_img = self._draw_stabilized_detections(frame_bgr, stabilized_detections)
            else:
                # Use ultralytics default rendering
                try:
                    dbg_img = r0.plot()
                except Exception:
                    dbg_img = frame_bgr

        return det_arr, dbg_img


def main():
    rospy.init_node("yolo26_ros1_node")
    node = Yolo26Ros1Node()

    if node.enable_cv_display:
        # Run display loop in main thread
        rate = rospy.Rate(30)  # 30Hz display update
        while not rospy.is_shutdown():
            if hasattr(node, '_display_img') and node._display_img is not None:
                cv2.imshow(node.cv_window_name, node._display_img)
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q') or key == 27:
                    rospy.signal_shutdown("User quit")
                    break
            rate.sleep()
    else:
        try:
            rospy.spin()
        except KeyboardInterrupt:
            pass


if __name__ == "__main__":
    main()
